from pathlib import Path
import albumentations as A
import cv2
import torch
import tqdm
from torch.nn import functional as F
from PIL import Image
from torchvision import transforms
import argparse
from albumentations.pytorch import ToTensorV2 as img_to_tensor
from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
from torchvision.utils import draw_segmentation_masks, make_grid, save_image

from Diff_based_AIGD.gmm_fun import *
from Diff_based_AIGD.utils import *
from TruFor_train_test.lib.config import *
from TruFor_train_test.lib.utils import *

def preprocessing(img):
    patchsize = 16
    totensor = torchvision.transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
        ])
    w,h = img.size
    if min(w,h) < patchsize:
        img = torchvision.transforms.Resize((patchsize,patchsize))(img)
    else:
        w = w // patchsize * patchsize
        h = h // patchsize * patchsize
        img = torchvision.transforms.CenterCrop((w,h))(img)
    img = totensor(img)
    patches = img.unfold(1, patchsize, patchsize).unfold(2, patchsize, patchsize)
    num_patches = patches.shape[1] * patches.shape[2]
    patches = patches.contiguous().view(3, num_patches, patchsize, patchsize)
    patches = patches.permute(1,0,2,3)
    a,b,c,d = patches.shape
    if a > 19200:
        patches = patches[0:19200,:,:,:]
    return patches

def diffusion_generated_detection(image_path):
    net = load_net(checkpoint_path='./Diff_based_AIGD/checkpoints_backbone/basic.pth') 
    with open('./Diff_based_AIGD/checkpoints_gmm/basic_genimage', 'rb') as file:
        gmm = pickle.load(file)
    
    TrainFeatures_base = torch.load('./Diff_based_AIGD/features/train/basic_genimage.pth')
    threshold = val_GMM_sklearn(modelpath='./Diff_based_AIGD/checkpoints_gmm/basic_genimage', features_baseline= TrainFeatures_base,rate=0.0005)
    print(threshold)
    img = Image.open(image_path).convert('RGB')
    img = preprocessing(img).cuda()
    # with torch.cuda.amp.autocast()
    with torch.no_grad():  # 确保不计算梯度
        f = net(img.unsqueeze(0))  # 前向传播
    # f = net(img.unsqueeze(0))
    likelihood = gmm.score_samples(f.detach().cpu())
    print(likelihood)
    if likelihood < threshold+200:
        return 'Not generated by diffusion'
    else:
        return 'Generated by diffusion'


def manipulation_detection(input_path,threshold=0.5):
    args = argparse.Namespace(
        input=input_path,
        experiment='trufor_ph3',
        opts=None,
        ckpt= "/home/chenhui/MMFakeBench/LLaVA_2/TruFor_train_test/pretrained_models/trufor.pth.tar"
    )

    update_config(config, args)
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    # Load the model
    print(f'Loading model from {args.ckpt}')
    checkpoint = torch.load(args.ckpt, map_location=device,weights_only=False)
    model = get_model(config)
    model.load_state_dict(checkpoint['state_dict'])
    model.to(device)
    model.eval()

    # Load the image
    transform = transforms.Compose([
        transforms.Resize((256, 256)),  # Resize to the expected input size
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
    ])

    image = Image.open(args.input).convert('RGB')
    image = transform(image).unsqueeze(0)  # Add batch dimension
    image = image.to(device)

    pred, _, det, _ = model(image)
    if det is not None:
        manipulation_score = torch.sigmoid(det).item()
    else:
        pred = F.softmax(pred, dim=1)
        manipulation_score = pred[:, 1].item()  # Assuming the second class is manipulation
    if manipulation_score > threshold:
        return 'Manipulated'
    else:
        return 'Not Manipulated'


# def manipulation_detection(input_path, threshold=0.5):
#     args = argparse.Namespace(
#         input=input_path,
#         experiment='trufor_ph3',
#         opts=None,
#         ckpt="/home/chenhui/MMFakeBench/LLaVA_2/TruFor_train_test/pretrained_models/trufor.pth.tar"
#     )

#     update_config(config, args)
#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

#     # Load the model
#     print(f'Loading model from {args.ckpt}')
#     checkpoint = torch.load(args.ckpt, map_location=device, weights_only=False)
#     model = get_model(config)
#     model.load_state_dict(checkpoint['state_dict'])
#     model.to(device)
#     model.eval()

#     # Load the image
#     transform = transforms.Compose([
#         transforms.Resize((256, 256)),  # Resize to the expected input size
#         transforms.ToTensor(),
#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
#     ])

#     try:
#         # 打开图片并处理格式
#         with Image.open(input_path) as img:
#             # 如果是JPG格式，在内存中转换为RGB模式
#             if input_path.lower().endswith(('.jpg', '.jpeg')):
#                 img = img.convert('RGB')
#                 print(f"已将 {input_path} 从JPG转换为RGB模式")
            
#             # 直接使用图片对象进行处理
#             image = transform(img).unsqueeze(0)  # Add batch dimension
#             image = image.to(device)

#         pred, _, det, _ = model(image)
#         if det is not None:
#             manipulation_score = torch.sigmoid(det).item()
#         else:
#             pred = F.softmax(pred, dim=1)
#             manipulation_score = pred[:, 1].item()  # Assuming the second class is manipulation
        
#         result = 'Manipulated' if manipulation_score > threshold else 'Not Manipulated'
        
#     except Exception as e:
#         print(f"图片处理失败: {e}")
#         raise

#     return result
# def diffusion_generated_detection(images):
#     results1 = [diffusion_generated(image_path) for image_path in images]
#     return results1

# def manipulation_detection(images):
#     results2 = [diffusion_generated(image_path) for image_path in images]
#     return results2


